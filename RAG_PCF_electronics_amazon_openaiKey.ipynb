{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwJq9pq6ozTKjn2UjxnnWp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessandrovicenti10/Tesi_Vicenti_ITPS_2025/blob/alessandro/RAG_PCF_electronics_amazon_openaiKey.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index\n",
        "!pip install llama_parse\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "blS-ggD7wrt9",
        "outputId": "ec5d3bde-bd1d-4ec6-813f-935bab2346b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama_index\n",
            "  Downloading llama_index-0.12.24-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama_index)\n",
            "  Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl.metadata (727 bytes)\n",
            "Collecting llama-index-cli<0.5.0,>=0.4.1 (from llama_index)\n",
            "  Downloading llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.13.0,>=0.12.24 (from llama_index)\n",
            "  Downloading llama_index_core-0.12.24.post1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama_index)\n",
            "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama_index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.9-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama_index)\n",
            "  Downloading llama_index_llms_openai-0.3.25-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama_index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
            "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama_index)\n",
            "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama_index)\n",
            "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
            "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama_index)\n",
            "  Downloading llama_index_readers_file-0.4.6-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama_index)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama_index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.61.1)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.24->llama_index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.24->llama_index) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.24->llama_index) (3.11.13)\n",
            "Collecting dataclasses-json (from llama-index-core<0.13.0,>=0.12.24->llama_index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.24->llama_index) (1.2.18)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.24->llama_index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.24->llama_index)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.24->llama_index) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.24->llama_index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.24->llama_index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.24->llama_index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.24->llama_index) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.24->llama_index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.24->llama_index) (2.10.6)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.24->llama_index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.24->llama_index) (9.0.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.13.0,>=0.12.24->llama_index)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.24->llama_index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.24->llama_index) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13.0,>=0.12.24->llama_index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.24->llama_index) (1.17.2)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama_index)\n",
            "  Downloading llama_cloud-0.1.14-py3-none-any.whl.metadata (902 bytes)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (4.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.2.2)\n",
            "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index)\n",
            "  Downloading pypdf-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_parse-0.6.4.post1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama_index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama_index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama_index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.24->llama_index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.24->llama_index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.24->llama_index) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.24->llama_index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.24->llama_index) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.24->llama_index) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.24->llama_index) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.6)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.24->llama_index) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.24->llama_index) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.24->llama_index) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.24->llama_index) (0.14.0)\n",
            "Collecting llama-cloud-services>=0.6.4 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_cloud_services-0.6.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.24->llama_index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.24->llama_index) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.24->llama_index) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.24->llama_index) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.24->llama_index) (3.1.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.24->llama_index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13.0,>=0.12.24->llama_index)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2025.1)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.24->llama_index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (1.17.0)\n",
            "Downloading llama_index-0.12.24-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.12.24.post1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.6.9-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_llms_openai-0.3.25-py3-none-any.whl (16 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.4.6-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_cloud-0.1.14-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.7/261.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.4.post1-py3-none-any.whl (4.9 kB)\n",
            "Downloading pypdf-5.3.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading llama_cloud_services-0.6.5-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, python-dotenv, pypdf, mypy-extensions, marshmallow, typing-inspect, tiktoken, llama-cloud, dataclasses-json, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama_index\n",
            "Successfully installed dataclasses-json-0.6.7 dirtyjson-1.0.8 filetype-1.2.0 llama-cloud-0.1.14 llama-cloud-services-0.6.5 llama-index-agent-openai-0.4.6 llama-index-cli-0.4.1 llama-index-core-0.12.24.post1 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.9 llama-index-llms-openai-0.3.25 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.6 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.4.post1 llama_index-0.12.24 marshmallow-3.26.1 mypy-extensions-1.0.0 pypdf-5.3.1 python-dotenv-1.0.1 striprtf-0.0.26 tiktoken-0.9.0 typing-inspect-0.9.0\n",
            "Requirement already satisfied: llama_parse in /usr/local/lib/python3.11/dist-packages (0.6.4.post1)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.4 in /usr/local/lib/python3.11/dist-packages (from llama_parse) (0.6.5)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama_parse) (8.1.8)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.14 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama_parse) (0.1.14)\n",
            "Requirement already satisfied: llama-index-core>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama_parse) (0.12.24.post1)\n",
            "Requirement already satisfied: pydantic!=2.10 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama_parse) (2.10.6)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama_parse) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.14->llama-cloud-services>=0.6.4->llama_parse) (2025.1.31)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.14->llama-cloud-services>=0.6.4->llama_parse) (0.28.1)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (3.11.13)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (2024.10.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (11.1.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (1.17.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.10->llama-cloud-services>=0.6.4->llama_parse) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.10->llama-cloud-services>=0.6.4->llama_parse) (2.27.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (1.18.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.14->llama-cloud-services>=0.6.4->llama_parse) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.14->llama-cloud-services>=0.6.4->llama_parse) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.14->llama-cloud-services>=0.6.4->llama_parse) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.14->llama-cloud-services>=0.6.4->llama_parse) (0.14.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (3.26.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.11.0->llama-cloud-services>=0.6.4->llama_parse) (24.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.14->llama-cloud-services>=0.6.4->llama_parse) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import json\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_parse import LlamaParse\n",
        "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
        "from IPython.display import Markdown\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Imposta API keys\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "llm_gpt4o_mini = OpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# Parser per il file CSV delle emissioni di materiali\n",
        "parser = LlamaParse(\n",
        "    api_key=userdata.get('LLAMA_CLOUD'),\n",
        "    result_type=\"markdown\",\n",
        ")\n",
        "\n",
        "# Carica il dataset delle emissioni di CO2\n",
        "co2_file_path = \"/content/sample_data/materials_co2_emission_gpt.csv\"\n",
        "documents = parser.load_data(co2_file_path)\n",
        "node_parser = MarkdownElementNodeParser(llm=llm_gpt4o_mini, num_workers=4)\n",
        "nodes = node_parser.get_nodes_from_documents(documents)\n",
        "base_nodes, objects = node_parser.get_nodes_and_objects(nodes)\n",
        "recursive_index = VectorStoreIndex(nodes=base_nodes + objects, llm=llm_gpt4o_mini)\n",
        "recursive_query_engine = recursive_index.as_query_engine(similarity_top_k=5, llm=llm_gpt4o_mini)\n",
        "\n",
        "# Carica il dataset di prodotti elettronici\n",
        "product_file_path = \"/content/sample_data/meta_Electronics_SMALL.jsonl\"\n",
        "products = []\n",
        "\n",
        "with open(product_file_path, \"r\") as file:\n",
        "    for line in file:\n",
        "        product = json.loads(line)\n",
        "        title = product.get(\"title\", \"Unknown Product\")\n",
        "        material = product.get(\"details\", {}).get(\"Material\", None)\n",
        "        if material:\n",
        "            products.append({\"title\": title, \"material\": material})\n",
        "\n",
        "# Genera ed esegue query per ogni prodotto\n",
        "for product in products[:10]:  # Limitiamo a 10 prodotti per test\n",
        "    query = f\"How much CO2 is emitted to produce a {product['title']} made from {product['material']}?\"\n",
        "    response = recursive_query_engine.query(query)\n",
        "    print(f\"\\n---------------------- CO2 Emission for {product['title']} ----------------------\")\n",
        "    display(Markdown(f\"{response}\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KynVTpu7wmJd",
        "outputId": "58cc966f-6440-4fb5-86e1-2f9b54a7d004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started parsing the file under job_id 24542e0a-a101-4b5a-bffb-ab9917ed1721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00, 9078.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------- CO2 Emission for Digi-Tatoo Decal Skin Compatible With MacBook Pro 13 inch (Model A2338/ A2289/ A2251) - Protective and Decorative Full Body Laptop Skin Decal Sticker, Anti-Scratch Vinly Skin Sticker Wrap [Fresh Marble] ----------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The carbon dioxide emissions associated with vinyl are not specified in the provided information. Therefore, it is not possible to determine the CO2 emissions for producing the Digi-Tatoo Decal Skin made from vinyl."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------- CO2 Emission for eForCity Leather Case with Stand for 7-Inch Samsung Galaxy Tab 2, White/Black Zebra (PSAMGLXTLC26) ----------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The CO2 emissions for producing a synthetic leather item, such as the eForCity Leather Case, would be associated with the material used. In this case, synthetic rubber, which has a CO2 emission of 3.5 kg per unit, could be a relevant comparison for synthetic leather. Therefore, the CO2 emissions for producing the case would be approximately 3.5 kg."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------- CO2 Emission for Outer Space Planets Stickers(50Pcs),Planetary Systems Waterproof Vinyl Water Bottle Stickers for Teens Girls Adults Kids,Laptop Car Cup Computer Guitar Skateboard Luggage Phone Aesthetic Stickers Pack ----------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The carbon dioxide emissions associated with producing vinyl are not specified in the provided information. Therefore, it is not possible to determine the CO2 emissions for the Outer Space Planets Stickers made from vinyl based on the available data."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------- CO2 Emission for Stanton STR8-100 Direct-Drive Digital Turntable with Straight Tone Arm (Discontinued by Manufacturer) ----------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The production of a Stanton STR8-100 Direct-Drive Digital Turntable made from aluminum emits 8.6 kilograms of CO2."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------- CO2 Emission for luo Cherry MX RGB Switch Mute Pink Switch Mute Gray Switch Genuine German Cherry Switch (10PCS, Cherry RGB Mute Gray Switch) ----------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The carbon dioxide emissions for producing a Cherry material are not specified in the provided information. Therefore, it is not possible to determine the CO2 emissions for the Cherry MX RGB Switch made from Cherry."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------- CO2 Emission for VFENG Premium 4-in-1 3M Full Body Skin Sticker Decals, Decorative Protective Skin for Microsoft Surface Book 3 13.5 Inch 13'' 2020+ (Core i5 Version) - Gray ----------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The CO2 emissions associated with producing a product made from Polyester is 6.0 kilograms per unit."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------- CO2 Emission for IU3D Low Noise DC 24V 0.12A 4010 Brushless Fan Cooler 40mm x 40mm x 10mm Cooling Fan. (2PCS -24V) ----------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The CO2 emissions for producing plastic materials vary depending on the specific type of plastic used. Common plastics and their associated emissions include:\n\n- Polycarbonate (PC): 5.2 kg\n- Polyethylene (PE): 2.0 kg\n- Polypropylene (PP): 1.8 kg\n- Polystyrene (PS): 3.2 kg\n- Polyethylene terephthalate (PET): 4.0 kg\n- Polyvinyl chloride (PVC): 2.4 kg\n- Acrylonitrile butadiene styrene (ABS): 4.2 kg\n- Nylon: 5.4 kg\n- Polymethylmethacrylate (PMMA): 6.0 kg\n- Thermoplastic elastomers (TPE): 4.5 kg\n\nTo determine the total CO2 emissions for the fan, the specific type of plastic used in its construction would be needed, as well as the quantity of plastic in the fan. If you can provide that information, I can help calculate the total emissions."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------- CO2 Emission for Cable Raceways - Floor Cord Protector Cable Shield Cord Cover PVC Floor Wire Protect ----------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The CO2 emissions associated with producing a product made from Polyvinyl chloride (PVC) is 2.4 kilograms per unit."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------- CO2 Emission for Nurse Stickers for Water Bottles and Laptop, Nursing Stickers for Nurse Students, Nurses, and Healthcare Workers, Waterproof, Reusable, No Residue Vinyl Decal Perfect Nurse Gift (108 Designs) ----------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The carbon dioxide emissions associated with vinyl are not specified in the provided information. Therefore, it is not possible to determine the CO2 emissions for producing the Nurse Stickers made from vinyl based on the available data."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------- CO2 Emission for AUGUR Travel Laptop Backpack ----------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The CO2 emissions associated with producing an AUGUR Travel Laptop Backpack made from Oxford are not specified in the provided information. Therefore, it is not possible to determine the CO2 emissions for that specific material."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import json\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_parse import LlamaParse\n",
        "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Imposta API keys\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "llm_gpt4o_mini = OpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# Parser per il file CSV delle emissioni di materiali\n",
        "parser = LlamaParse(\n",
        "    api_key=userdata.get('LLAMA_CLOUD'),\n",
        "    result_type=\"markdown\",\n",
        ")\n",
        "\n",
        "# Carica il dataset delle emissioni di CO2\n",
        "co2_file_path = \"/content/sample_data/materials_co2_emission_gpt.csv\"\n",
        "documents = parser.load_data(co2_file_path)\n",
        "node_parser = MarkdownElementNodeParser(llm=llm_gpt4o_mini, num_workers=4)\n",
        "nodes = node_parser.get_nodes_from_documents(documents)\n",
        "base_nodes, objects = node_parser.get_nodes_and_objects(nodes)\n",
        "recursive_index = VectorStoreIndex(nodes=base_nodes + objects, llm=llm_gpt4o_mini)\n",
        "recursive_query_engine = recursive_index.as_query_engine(similarity_top_k=5, llm=llm_gpt4o_mini)\n",
        "\n",
        "# Materiali comuni per alcune categorie di prodotti\n",
        "common_materials = {\n",
        "    \"fan\": \"Polycarbonate (PC)\",\n",
        "    \"cable\": \"Polyvinyl chloride (PVC)\",\n",
        "    \"case\": \"Acrylonitrile butadiene styrene (ABS)\",\n",
        "    \"battery\": \"Lithium-ion\",\n",
        "    \"screen\": \"Glass\"\n",
        "}\n",
        "\n",
        "# Carica il dataset di prodotti elettronici\n",
        "product_file_path = \"/content/sample_data/meta_Electronics_SMALL.jsonl\"\n",
        "products = []\n",
        "\n",
        "with open(product_file_path, \"r\") as file:\n",
        "    for line in file:\n",
        "        product = json.loads(line)\n",
        "        title = product.get(\"title\", \"Unknown Product\")\n",
        "        material = product.get(\"details\", {}).get(\"Material\", None)\n",
        "\n",
        "        # Se il materiale non è specificato, usa il materiale comune più probabile\n",
        "        if not material:\n",
        "            for key, common_material in common_materials.items():\n",
        "                if key in title.lower():\n",
        "                    material = common_material\n",
        "                    break\n",
        "\n",
        "        if material:\n",
        "            products.append({\"title\": title, \"material\": material})\n",
        "\n",
        "# Genera ed esegue query per ogni prodotto\n",
        "results = []\n",
        "for product in products[:10]:  # Limitiamo a 10 prodotti per test\n",
        "    query = f\"How much CO2 is emitted to produce a {product['title']} made from {product['material']}, give me only value number with measurement unit else 'no value'?\"\n",
        "    response = recursive_query_engine.query(query)\n",
        "\n",
        "    results.append({\n",
        "        \"product\": product[\"title\"],\n",
        "        \"material\": product[\"material\"],\n",
        "        \"co2_emission\": str(response)  # Convertiamo in stringa per evitare problemi di formattazione\n",
        "    })\n",
        "\n",
        "# Stampa output in formato JSON\n",
        "print(json.dumps(results, indent=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIrfaMou4nCS",
        "outputId": "9754c047-8737-4933-8ada-1dfbe7d6cbb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started parsing the file under job_id 961aebc0-13da-4d37-bfa9-75b1b0faf6c6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00, 9137.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"product\": \"Digi-Tatoo Decal Skin Compatible With MacBook Pro 13 inch (Model A2338/ A2289/ A2251) - Protective and Decorative Full Body Laptop Skin Decal Sticker, Anti-Scratch Vinly Skin Sticker Wrap [Fresh Marble]\",\n",
            "        \"material\": \"Vinyl\",\n",
            "        \"co2_emission\": \"no value\"\n",
            "    },\n",
            "    {\n",
            "        \"product\": \"MOSISO Plastic Hard Shell Case & Keyboard Cover Compatible MacBook Air 11 Inch (Models: A1370 & A1465), Transparent Black\",\n",
            "        \"material\": \"Acrylonitrile butadiene styrene (ABS)\",\n",
            "        \"co2_emission\": \"4.2 kg\"\n",
            "    },\n",
            "    {\n",
            "        \"product\": \"Fishfinder, Depth Finder Poly Sun Cover for 3\\\" - 4\\\" Models - Protects Your Screen from Sun / Weather Damage\",\n",
            "        \"material\": \"Glass\",\n",
            "        \"co2_emission\": \"1.2 kg\"\n",
            "    },\n",
            "    {\n",
            "        \"product\": \"Dock Audio Extender Adapter Converter Cable for iPod iPhone 4 4S iPhone 5 5S iPad, Samsung & Other Smart Phones\",\n",
            "        \"material\": \"Polyvinyl chloride (PVC)\",\n",
            "        \"co2_emission\": \"2.4 kg\"\n",
            "    },\n",
            "    {\n",
            "        \"product\": \"eForCity Leather Case with Stand for 7-Inch Samsung Galaxy Tab 2, White/Black Zebra (PSAMGLXTLC26)\",\n",
            "        \"material\": \"Synthetic Leather with Suede Interior\",\n",
            "        \"co2_emission\": \"no value\"\n",
            "    },\n",
            "    {\n",
            "        \"product\": \"Outer Space Planets Stickers(50Pcs),Planetary Systems Waterproof Vinyl Water Bottle Stickers for Teens Girls Adults Kids,Laptop Car Cup Computer Guitar Skateboard Luggage Phone Aesthetic Stickers Pack\",\n",
            "        \"material\": \"Vinyl\",\n",
            "        \"co2_emission\": \"no value\"\n",
            "    },\n",
            "    {\n",
            "        \"product\": \"Leather Case for Cp S6/S7C\",\n",
            "        \"material\": \"Acrylonitrile butadiene styrene (ABS)\",\n",
            "        \"co2_emission\": \"4.2 kg\"\n",
            "    },\n",
            "    {\n",
            "        \"product\": \"Stanton STR8-100 Direct-Drive Digital Turntable with Straight Tone Arm (Discontinued by Manufacturer)\",\n",
            "        \"material\": \"Aluminum\",\n",
            "        \"co2_emission\": \"8.6 kg\"\n",
            "    },\n",
            "    {\n",
            "        \"product\": \"luo Cherry MX RGB Switch Mute Pink Switch Mute Gray Switch Genuine German Cherry Switch (10PCS, Cherry RGB Mute Gray Switch)\",\n",
            "        \"material\": \"Cherry\",\n",
            "        \"co2_emission\": \"no value\"\n",
            "    },\n",
            "    {\n",
            "        \"product\": \"HP Elitebook 8560W New Replacement LCD Screen for Laptop LED HD Matte\",\n",
            "        \"material\": \"Glass\",\n",
            "        \"co2_emission\": \"1.2 kg\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    }
  ]
}